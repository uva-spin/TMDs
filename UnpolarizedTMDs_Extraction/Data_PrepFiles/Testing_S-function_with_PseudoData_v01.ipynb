{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's define our function to generate pseudo-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sfunction(k,Q2):\n",
    "    return 1/(k**2+Q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's define the range of $Q^2$ values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n"
     ]
    }
   ],
   "source": [
    "Q2vals = np.array(np.linspace(1,10,10))\n",
    "print(Q2vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Simpson's rule for numerical integraton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpsons_rule(f, a, b, N):\n",
    "    h = (b - a) / N\n",
    "    x = np.linspace(a, b, N+1)\n",
    "    y = f(x)\n",
    "    return h/3 * np.sum(y[0:-1:2] + 4*y[1::2] + y[2::2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate FUU values for the given $Q^2$ values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_min = 0 \n",
    "k_max = 1\n",
    "def FUU(Q2arr):\n",
    "    Fvals = []\n",
    "    for Q2 in Q2arr:\n",
    "        def integrand(k):\n",
    "            return Sfunction(k, Q2)\n",
    "        # Perform the integration using Simpson's rule\n",
    "        integral = simpsons_rule(integrand, k_min, k_max, 100)\n",
    "        Fvals.append(integral)\n",
    "    return np.array(Q2arr), np.array(Fvals)\n",
    "\n",
    "Q2, Fvals = FUU(Q2vals)\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({'Q2': Q2, 'FUU': Fvals})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q2</th>\n",
       "      <th>FUU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.785398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.435210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.302300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.231824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.188069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.158236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.136584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.120150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.107250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.096853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Q2       FUU\n",
       "0   1.0  0.785398\n",
       "1   2.0  0.435210\n",
       "2   3.0  0.302300\n",
       "3   4.0  0.231824\n",
       "4   5.0  0.188069\n",
       "5   6.0  0.158236\n",
       "6   7.0  0.136584\n",
       "7   8.0  0.120150\n",
       "8   9.0  0.107250\n",
       "9  10.0  0.096853"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def DNN_model():\n",
    "#     model = tf.keras.Sequential([\n",
    "#         layers.Dense(64, activation='relu', input_shape=(2,)),  # Adjust input shape to (2,)\n",
    "#         layers.Dense(64, activation='relu'),\n",
    "#         layers.Dense(1)  # Output layer\n",
    "#     ])\n",
    "#     return model\n",
    "\n",
    "# def DNN_model():\n",
    "#     model = tf.keras.Sequential([\n",
    "#         layers.Dense(128, activation='relu', input_shape=(2,)),\n",
    "#         layers.Dense(256, activation='relu'),\n",
    "#         layers.Dense(128, activation='relu'),\n",
    "#         layers.Dense(64, activation='relu'),\n",
    "#         layers.Dense(1)  # Output layer\n",
    "#     ])\n",
    "#     return model\n",
    "\n",
    "L1_reg = 0.000001\n",
    "\n",
    "def DNN_model(hidden_layers=2, width=5, activation='relu'):\n",
    "    inp = tf.keras.Input(shape=(2,))\n",
    "    initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=42)\n",
    "    x = tf.keras.layers.Dense(width, activation=activation, kernel_initializer=initializer, activity_regularizer=tf.keras.regularizers.L1(L1_reg))(inp)\n",
    "    x1 = tf.keras.layers.Dense(width, activation=activation, kernel_initializer=initializer, activity_regularizer=tf.keras.regularizers.L1(L1_reg))(x)\n",
    "    x2 = tf.keras.layers.Dense(width, activation=activation, kernel_initializer=initializer, activity_regularizer=tf.keras.regularizers.L1(L1_reg))(x1)\n",
    "    nnout = tf.keras.layers.Dense(1, kernel_initializer=initializer)(x2)\n",
    "    mod = tf.keras.Model(inp, nnout)\n",
    "    return mod\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's define the integration layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrapezoidalIntegrationLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(TrapezoidalIntegrationLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Smodel, tempk = inputs\n",
    "        \n",
    "        # Assuming 'k' is the second dimension\n",
    "        delta_k = tempk[:, 1:] - tempk[:, :-1]\n",
    "        integrand = (Smodel[:, 1:] + Smodel[:, :-1]) / 2.0\n",
    "        trapz_integrated = tf.reduce_sum(integrand * delta_k, axis=1)\n",
    "        return trapz_integrated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's define the FUU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integralmodel():\n",
    "    tempk = tf.keras.Input(shape=(1), name='k')\n",
    "    tempQ2 = tf.keras.Input(shape=(1), name='Q2')\n",
    "    #tempk = np.linspace(0, 1, 100)\n",
    "    \n",
    "    # Create an instance of the DNN model\n",
    "    inputVals = tf.keras.layers.Concatenate()([tempk, tempQ2])\n",
    "    dnn_model = DNN_model()(inputVals)\n",
    "    \n",
    "    # Apply TrapezoidalIntegrationLayer\n",
    "    integrated_Smodel = TrapezoidalIntegrationLayer()([dnn_model, tempk])\n",
    "    int_result = tf.keras.layers.Layer()([integrated_Smodel])\n",
    "    \n",
    "    return tf.keras.Model([tempk, tempQ2], int_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate and Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "FUUmodel = integralmodel()\n",
    "FUUmodel.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Q2']\n",
    "y = df['FUU']\n",
    "\n",
    "# Splitting data manually\n",
    "split_ratio = 0\n",
    "split_index = int(len(X) * (1 - split_ratio))\n",
    "X_train, X_val = X[:split_index], X[split_index:]\n",
    "y_train, y_val = y[:split_index], y[split_index:]\n",
    "\n",
    "k_array = np.linspace(0, 1, len(X_train))  # Adjust length to match X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.1066\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1066\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1066\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1066\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1066\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1066\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1066\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1066\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1066\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1066\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1066\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1066\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1066\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1066\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1066\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1066\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1066\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1066\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1066\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1066\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1066\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1066\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1066\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1066\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1066\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1066\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1066\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1066\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1066\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1066\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1066\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1066\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1066\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1066\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1066\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1066\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1066\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1066\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1066\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1066\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1066\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1066\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1066\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1066\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1066\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1066\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1066\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1066\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1066\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1066\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1066\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1066\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1066\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1066\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1066\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1066\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1066\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1066\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1066\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1066\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1066\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1066\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1066\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1066\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1066\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1066\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1066\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1066\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1066\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1066\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1066\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1066\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1066\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1066\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1066\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1066\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1066\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1066\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1066\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1066\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1066\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1066\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1066\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1066\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1066\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1066\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1066\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1066\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1066\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1066\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1066\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1066\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1066\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1066\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1066\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1066\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1066\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1066\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1066\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe9a472abe0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "FUUmodel.fit([X_train, k_array.reshape(-1, 1)], y_train, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
